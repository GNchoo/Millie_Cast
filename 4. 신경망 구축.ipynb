{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import preprocessing\n",
    "from keras.layers import Input,Embedding,Dense, Dropout, convolutional,Conv1D, GlobalMaxPooling1D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN -> 합성곱 신경망 챗봇 데이터 훈련\n",
    "# 라벨 0:일상, 1:이별, 2:사랑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/chatbot_data.csv\", delimiter=\",\")\n",
    "feature = data['Q'].to_list()\n",
    "label = data['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 토크나이징\n",
    "# 단어 시퀸스 : 단어를 토큰화해서 순서대로 리스트에 담는 것\n",
    "\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in feature]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "suqunce = tokenizer.texts_to_sequences(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 패딩 이용해서 입력데이터 길이 맞추기\n",
    "pad_seq = keras.utils.pad_sequences(suqunce, maxlen=15, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트, 테스트세트, 검증세트\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((pad_seq, label))\n",
    "ds = ds.shuffle(len(feature))\n",
    "\n",
    "train_size = int(len(pad_seq)*0.7)\n",
    "val_size = int(len(pad_seq)*0.2)\n",
    "test_size = int(len(pad_seq)*0.1)\n",
    "\n",
    "# trai_ds -> input, target, batch\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "\n",
    "# 하이퍼 파라미터\n",
    "EMB_SIZE = 128 # 임베딩 벡터의 길이\n",
    "EPOCH = 5\n",
    "VOCA_SIZE = len(word_index) + 1 # 전체 단어의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 함수형으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "input_layer = Input(shape=(15,))\n",
    "\n",
    "# embedding layer\n",
    "embedding_layer = Embedding(VOCA_SIZE, EMB_SIZE, input_length=15)(input_layer)\n",
    "\n",
    "# dropout layer\n",
    "dropout_emb = Dropout(rate=0.5)(embedding_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱(3-gram, 4-gram, 5-gram)\n",
    "conv1 = Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu')(dropout_emb)\n",
    "pool1 = GlobalMaxPooling1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(filters=128, kernel_size=4, padding='valid', activation='relu')(dropout_emb)\n",
    "pool2 = GlobalMaxPooling1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(filters=128, kernel_size=5, padding='valid', activation='relu')(dropout_emb)\n",
    "pool3 = GlobalMaxPooling1D()(conv3)\n",
    "\n",
    "concat = concatenate([pool1, pool2, pool3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밀집층\n",
    "hidden = Dense(128, activation='relu')(concat)\n",
    "\n",
    "# 드롭아웃\n",
    "dropout_hidden= Dropout(rate= 0.5)(hidden)\n",
    "\n",
    "# 밀집층\n",
    "pred = Dense(3, activation='softmax')(dropout_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      1715072     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 15, 128)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 13, 128)      49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 128)      65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 11, 128)      82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            387         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,961,731\n",
      "Trainable params: 1,961,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Model(input_layer, pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "414/414 [==============================] - 16s 33ms/step - loss: 0.8948 - accuracy: 0.5592 - val_loss: 0.6167 - val_accuracy: 0.7720\n",
      "Epoch 2/5\n",
      "414/414 [==============================] - 14s 33ms/step - loss: 0.5239 - accuracy: 0.8007 - val_loss: 0.2718 - val_accuracy: 0.9175\n",
      "Epoch 3/5\n",
      "414/414 [==============================] - 13s 32ms/step - loss: 0.3092 - accuracy: 0.8980 - val_loss: 0.1455 - val_accuracy: 0.9556\n",
      "Epoch 4/5\n",
      "414/414 [==============================] - 13s 32ms/step - loss: 0.1958 - accuracy: 0.9393 - val_loss: 0.0864 - val_accuracy: 0.9797\n",
      "Epoch 5/5\n",
      "414/414 [==============================] - 13s 32ms/step - loss: 0.1351 - accuracy: 0.9587 - val_loss: 0.0658 - val_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2266ec5b670>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=EPOCH, validation_data=val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06201406195759773, 0.9830795526504517]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 분류\n",
    "# 테스트용 데이터셋\n",
    "ds = tf.data.Dataset.from_tensor_slices((pad_seq, label))\n",
    "ds = ds.shuffle(len(feature))\n",
    "test_ds = ds.take(2000).batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06409832835197449, 0.9815000295639038]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('cnn.h5')\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['좋아하는', '여자의', '단점을', '들었는데', '어떻게', '해야할지', '모르겠어', '답답해']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 데이터셋\n",
    "# 답러닝 모델을 거친 예측값 비교\n",
    "\n",
    "# 단어 시퀀스\n",
    "corpus[11238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  3970,  4570, 12909,    12,   794,    71,   631,     0,\n",
       "           0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 인덱스 시퀀스\n",
    "pad_seq[11238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[11238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.6500855e-06, 4.3452792e-06, 9.9999201e-01], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(pad_seq)\n",
    "pred[11238]\n",
    "\n",
    "# softmax\n",
    "# 2번 클래스일 확률 0.9990"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy -> 형태소 분석기 3개\n",
    "# Okt, kkma, komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 토큰화, 품사 태깅\n",
    "# 형태소 : 의미가 있는 가장 작은 말의 단위\n",
    "# 형태소를 토큰 단위로 사용해서 단어와 품사 정보를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 -> 띄어쓰기를 기준으로 토큰화 시킬 수 있는데 한글은 불가능\n",
    "\n",
    "# 지원하는 품사 갯수 : kkma > komoran > okt\n",
    "# 정확도 : kkma > komoran > okt\n",
    "# 속도 : kkma < komoran < okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수', '는', '오렌지', '하나', '를', '사', '아', '오', '았', '다']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 추출\n",
    "text = '철수는 오렌지 하나를 사왔다'\n",
    "\n",
    "morph = kkma.morphs(text)\n",
    "morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('철수', 'NNG'),\n",
       " ('는', 'JX'),\n",
       " ('오렌지', 'NNG'),\n",
       " ('하나', 'NNG'),\n",
       " ('를', 'JKO'),\n",
       " ('사', 'VV'),\n",
       " ('아', 'ECS'),\n",
       " ('오', 'VX'),\n",
       " ('았', 'EPT'),\n",
       " ('다', 'EFN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 품사 태깅\n",
    "pos = kkma.pos(text)\n",
    "pos\n",
    "\n",
    "# NNG -> 일반명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수', '오렌지', '하나']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = kkma.nouns(text)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수는 오렌지 하나를 사 왔다.', '영희는 사과를 두개 사 왔다']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합문장 분리\n",
    "text = '철수는 오렌지 하나를 사왔다. 영희는 사과를 두개 사왔다'\n",
    "sentences = kkma.sentences(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['철수', '는', '오렌지', '하나', '를', '사', '아', '오', '았', '다', '.'],\n",
       " [('철수', 'NNP'),\n",
       "  ('는', 'JX'),\n",
       "  ('오렌지', 'NNP'),\n",
       "  ('하나', 'NR'),\n",
       "  ('를', 'JKO'),\n",
       "  ('사', 'VV'),\n",
       "  ('아', 'EC'),\n",
       "  ('오', 'VX'),\n",
       "  ('았', 'EP'),\n",
       "  ('다', 'EF'),\n",
       "  ('.', 'SF')],\n",
       " ['철수', '오렌지'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# komoran\n",
    "Komoran = Komoran()\n",
    "text = '철수는 오렌지 하나를 사왔다.'\n",
    "\n",
    "morph = Komoran.morphs(text)\n",
    "pos = Komoran.pos(text)\n",
    "nouns = Komoran.nouns(text)\n",
    "\n",
    "morph, pos, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['철수', '는', '오렌지', '하나', '를', '사왔다', '.'],\n",
       " [('철수', 'Noun'),\n",
       "  ('는', 'Josa'),\n",
       "  ('오렌지', 'Noun'),\n",
       "  ('하나', 'Noun'),\n",
       "  ('를', 'Josa'),\n",
       "  ('사왔다', 'Verb'),\n",
       "  ('.', 'Punctuation')],\n",
       " ['철수', '오렌지', '하나'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# okt\n",
    "Okt = Okt()\n",
    "\n",
    "text = '철수는 오렌지 하나를 사왔다.'\n",
    "\n",
    "morph = Okt.morphs(text)\n",
    "pos = Okt.pos(text)\n",
    "nouns = Okt.nouns(text)\n",
    "\n",
    "morph, pos, nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날씨가 좋아요ㅋㅋㅋ\n",
      "['오늘', '오늘 날씨', '좋아욬', '날씨']\n"
     ]
    }
   ],
   "source": [
    "# Okt 지원함수 두개\n",
    "\n",
    "# 구어체\n",
    "text = '오늘 날씨가 좋아욬ㅋㅋㅋ'\n",
    "# 정규화 (구어체, 오타 잡아줌)\n",
    "print(Okt.normalize(text))\n",
    "\n",
    "# 어구추출\n",
    "print(Okt.phrases(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'NP'),\n",
       " ('는', 'JX'),\n",
       " ('영화', 'NNG'),\n",
       " ('나', 'NP'),\n",
       " ('는', 'JX'),\n",
       " ('내일', 'NNG'),\n",
       " (',', 'SP'),\n",
       " ('어제', 'NNP'),\n",
       " ('의', 'JKG'),\n",
       " ('너', 'NP'),\n",
       " ('와', 'JKB'),\n",
       " ('만나', 'VV'),\n",
       " ('ㄴ다', 'EC'),\n",
       " ('를', 'JKO'),\n",
       " ('보', 'VV'),\n",
       " ('ㄹ', 'ETM'),\n",
       " ('거', 'NNB'),\n",
       " ('야', 'JX')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"나는 영화 나는 내일, 어제의 너와 만난다를 볼거야\"\n",
    "\n",
    "pos = Komoran.pos(text)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'NP'),\n",
       " ('는', 'JX'),\n",
       " ('영화', 'NNG'),\n",
       " ('나는 내일, 어제의 너와 만난다', 'NNG'),\n",
       " ('를', 'JKO'),\n",
       " ('보', 'VV'),\n",
       " ('ㄹ', 'ETM'),\n",
       " ('거', 'NNB'),\n",
       " ('야', 'JX')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 사전 -> 단어 추가\n",
    "Komoran = Komoran(userdic=\"./data/user_dic.tsv\")\n",
    "\n",
    "text = \"나는 영화 나는 내일, 어제의 너와 만난다를 볼거야\"\n",
    "\n",
    "pos = Komoran.pos(text)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 의미를 분석해서 실수 벡터로 바꿔주는 기법\n",
    "\n",
    "komoran = Komoran()\n",
    "text = '오늘 날씨는 구름이 많아요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨', '구름']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원 핫 인코딩\n",
    "\n",
    "nouns = komoran.nouns(text)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'오늘': 0, '날씨': 1, '구름': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1,0,0] -> 오늘\n",
    "# [0,1,0] -> 날씨\n",
    "# [0,0,1] -> 구름\n",
    "\n",
    "# 단어 사전 구축, 단어별 인덱스 부여\n",
    "\n",
    "dic = {}\n",
    "for word in nouns:\n",
    "    if word not in dic.keys():\n",
    "        dic[word] = len(dic)\n",
    "\n",
    "dic\n",
    "# key : 단어, value : 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = len(dic)\n",
    "target = list(dic.values())\n",
    "# np.eye -> 단위행렬\n",
    "# 단어 사전의 길이만큼 단위행렬\n",
    "oh_target = np.eye(nb)[target]\n",
    "oh_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어사전의 크기가 커지면 원 핫 인코딩을 사용했을 떄, 메모리도 낭비되고 훈련시간 길어짐\n",
    "# -> 단어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 -> word2vec\n",
    "# gensim\n",
    "\n",
    "# word2vec 두가지 모델\n",
    "# 1. CBOW -> 주변 단어를 통해서 타깃 단어를 예측\n",
    "# 2. skip-gram -> 타깃 단어를 통해서 주변 단어를 예측\n",
    "# 오늘 날씨는 구름이 많아요\n",
    "# CBOW\n",
    "# 오늘 __는 구름이 많아요\n",
    "# 타깃 단어 : 날씨, 주변단어 오늘, 구름\n",
    "\n",
    "# skip-gram\n",
    "# __ 날씨는 __이 많아요\n",
    "# 주변 단어 : 오늘, 구름 -> 타깃 단어 : 날씨\n",
    "\n",
    "# window : 주변 단어의 갯수\n",
    "# window가 1이면 타깃 단어 앞뒤로 1개씩 주변단어로 보는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "\n",
    "def read_review_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f :\n",
    "        # f.read().splitlines() 줄별로 잘라서 읽은 것\n",
    "        # line.split('\\t') 줄별로 자른거 -> 탭 기준으로 문장을 자른 것\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "1. 파일 읽어오기 완료 :  0.40199756622314453\n",
      "2. 명사 추출 완료 :  225.29833984375\n",
      "3. word2vec 모델 학습 완료 :  237.06633305549622\n",
      "4. 모델 저장 완료 :  237.1043348312378\n",
      "200000\n",
      "1076896\n"
     ]
    }
   ],
   "source": [
    "# 수행속도 확인\n",
    "start = time.time()\n",
    "\n",
    "# 파일 읽어오기\n",
    "review_data = read_review_data(\"./data/ratings.txt\")\n",
    "print(len(review_data))\n",
    "print(\"1. 파일 읽어오기 완료 : \", time.time() - start)\n",
    "\n",
    "# 문장별로 명사만 추출해서 입력 데이터 만들기\n",
    "Komoran = Komoran()\n",
    "docs = [Komoran.nouns(sentences[1]) for sentences in review_data]\n",
    "print(\"2. 명사 추출 완료 : \", time.time() - start)\n",
    "\n",
    "# word2vec 모델 훈련\n",
    "# sentences : 문장데이터\n",
    "# vector_size : 단어 임베딩 된 벡터의 크기\n",
    "# window : 주변 단어의 갯수\n",
    "# min_count : 단어 최소 빈도수 (빈도수 이하의 단어는 카운트 안됨)\n",
    "# sg : 0(CBOW) / 1(skip-gram)\n",
    "model = Word2Vec(sentences=docs, vector_size=200, window=4, min_count=2, sg=1)\n",
    "print(\"3. word2vec 모델 학습 완료 : \", time.time() - start)\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"embedding.model\")\n",
    "print(\"4. 모델 저장 완료 : \", time.time() - start)\n",
    "\n",
    "# 리뷰 갯수\n",
    "print(model.corpus_count)\n",
    "\n",
    "# 학습한 단어 갯수\n",
    "print(model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1993c3d8f70>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 모델 이용해서 확인\n",
    "model = Word2Vec.load('./embedding.model')\n",
    "\n",
    "# 단어 임베딩 벡터\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91994405"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='일요일', w2='월요일')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7024495"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='안성기', w2='배우')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4075816"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='일요일', w2='배우')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('양동근', 0.946983814239502),\n",
       " ('박신양', 0.9388031363487244),\n",
       " ('정려원', 0.9386017322540283),\n",
       " ('재발견', 0.9378085136413574),\n",
       " ('심은하', 0.9377965331077576)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 유사한 단어\n",
    "model.wv.most_similar(\"안성기\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영화 장르', 0.8765575289726257),\n",
       " ('물이', 0.8629868626594543),\n",
       " ('분류', 0.8422165513038635),\n",
       " ('정통', 0.8385854959487915),\n",
       " ('혼합', 0.8363239765167236)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"장르\", topn=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
